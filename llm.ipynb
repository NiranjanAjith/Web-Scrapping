{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d35e54556bf410fb9b3d5c0b5703ae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/623 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadhi\\anaconda3\\envs\\tf\\lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\aadhi\\.cache\\huggingface\\hub\\models--mistralai--Mistral-Nemo-Instruct-2407. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.mistral.modeling_tf_mistral because of the following error (look up to see its traceback):\nnumpy.core.multiarray failed to import (auto-generated because you didn't call 'numpy.import_array()' after cimporting numpy; use '<void>numpy._import_array' to disable if you are certain you don't need it).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\utils\\import_utils.py:1567\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:850\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\mistral\\modeling_tf_mistral.py:33\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_tf_outputs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     29\u001b[0m     TFBaseModelOutputWithPast,\n\u001b[0;32m     30\u001b[0m     TFCausalLMOutputWithPast,\n\u001b[0;32m     31\u001b[0m     TFSequenceClassifierOutputWithPast,\n\u001b[0;32m     32\u001b[0m )\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_tf_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     34\u001b[0m     TFCausalLanguageModelingLoss,\n\u001b[0;32m     35\u001b[0m     TFPreTrainedModel,\n\u001b[0;32m     36\u001b[0m     TFSequenceClassificationLoss,\n\u001b[0;32m     37\u001b[0m     get_initializer,\n\u001b[0;32m     38\u001b[0m     get_tf_activation,\n\u001b[0;32m     39\u001b[0m     keras,\n\u001b[0;32m     40\u001b[0m     keras_serializable,\n\u001b[0;32m     41\u001b[0m     unpack_inputs,\n\u001b[0;32m     42\u001b[0m )\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_embeddings_within_bounds, shape_list, stable_softmax\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_tf_utils.py:32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, Any, Callable, Dict, List, Optional, Union\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mh5py\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\h5py\\__init__.py:45\u001b[0m\n\u001b[0;32m     43\u001b[0m _errors\u001b[38;5;241m.\u001b[39msilence_errors()\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_conv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_converters \u001b[38;5;28;01mas\u001b[39;00m _register_converters, \\\n\u001b[0;32m     46\u001b[0m                    unregister_converters \u001b[38;5;28;01mas\u001b[39;00m _unregister_converters\n\u001b[0;32m     47\u001b[0m _register_converters()\n",
      "File \u001b[1;32mh5py\\\\_conv.pyx:1\u001b[0m, in \u001b[0;36minit h5py._conv\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\h5r.pyx:1\u001b[0m, in \u001b[0;36minit h5py.h5r\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\h5p.pyx:1\u001b[0m, in \u001b[0;36minit h5py.h5p\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\h5t.pyx:1\u001b[0m, in \u001b[0;36minit h5py.h5t\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import (auto-generated because you didn't call 'numpy.import_array()' after cimporting numpy; use '<void>numpy._import_array' to disable if you are certain you don't need it).",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Authenticate and create pipeline\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistralai/Mistral-Nemo-Instruct-2407\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m pipe \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-generation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      8\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWho are you?\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m      9\u001b[0m ]\n\u001b[0;32m     10\u001b[0m response \u001b[38;5;241m=\u001b[39m pipe(messages)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\pipelines\\__init__.py:895\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    894\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[1;32m--> 895\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m infer_framework_load_model(\n\u001b[0;32m    896\u001b[0m         model,\n\u001b[0;32m    897\u001b[0m         model_classes\u001b[38;5;241m=\u001b[39mmodel_classes,\n\u001b[0;32m    898\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m    899\u001b[0m         framework\u001b[38;5;241m=\u001b[39mframework,\n\u001b[0;32m    900\u001b[0m         task\u001b[38;5;241m=\u001b[39mtask,\n\u001b[0;32m    901\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs,\n\u001b[0;32m    902\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m    903\u001b[0m     )\n\u001b[0;32m    905\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m    906\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\pipelines\\base.py:258\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    256\u001b[0m         classes\u001b[38;5;241m.\u001b[39mappend(_class)\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m look_tf:\n\u001b[1;32m--> 258\u001b[0m     _class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransformers_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTF\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43marchitecture\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    260\u001b[0m         classes\u001b[38;5;241m.\u001b[39mappend(_class)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\utils\\import_utils.py:1558\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1557\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m-> 1558\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1560\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\utils\\import_utils.py:1557\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1555\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1557\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1558\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\utils\\import_utils.py:1569\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1570\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1571\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1572\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.models.mistral.modeling_tf_mistral because of the following error (look up to see its traceback):\nnumpy.core.multiarray failed to import (auto-generated because you didn't call 'numpy.import_array()' after cimporting numpy; use '<void>numpy._import_array' to disable if you are certain you don't need it)."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Authenticate and create pipeline\n",
    "model_name = \"mistralai/Mistral-Nemo-Instruct-2407\"\n",
    "pipe = pipeline(\"text-generation\", model=model_name, use_auth_token=True)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "response = pipe(messages)\n",
    "print(response)\n",
    "\n",
    "def generate_search_phrases(topic, num_phrases=5, max_length=30):\n",
    "    \"\"\"\n",
    "    Generate search phrases based on the given topic.\n",
    "    \n",
    "    Args:\n",
    "    topic (str): The input topic.\n",
    "    num_phrases (int): Number of phrases to generate.\n",
    "    max_length (int): Maximum length of each generated phrase.\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of generated search phrases.\n",
    "    \"\"\"\n",
    "    # Load model and tokenizer\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=True)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=True)\n",
    "    \n",
    "    # Step 2: Define input text\n",
    "    input_text = f\"Search phrases about {topic}:\"\n",
    "    \n",
    "    # Step 3: Tokenize the input\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "    \n",
    "    # Generate text\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,\n",
    "        num_return_sequences=num_phrases,\n",
    "        no_repeat_ngram_size=2,\n",
    "        do_sample=True,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    # Step 4: Decode the generated tokens to form search phrases\n",
    "    search_phrases = [tokenizer.decode(ids, skip_special_tokens=True) for ids in output]\n",
    "    \n",
    "    # Remove the input text from the generated phrases\n",
    "    search_phrases = [phrase.replace(input_text, \"\").strip() for phrase in search_phrases]\n",
    "    \n",
    "    return search_phrases\n",
    "\n",
    "# Example usage\n",
    "topic = \"artificial intelligence\"\n",
    "generated_phrases = generate_search_phrases(topic)\n",
    "\n",
    "print(f\"Generated search phrases about {topic}:\")\n",
    "for i, phrase in enumerate(generated_phrases, 1):\n",
    "    print(f\"{i}. {phrase}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video file C:\\dmvr\\examples\\train\\train_splits\\dia125_utt3.mp4 does not exist.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e059e9375a436b915df1edbfb8a41b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x81 in position 32549: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 24\u001b[0m\n\u001b[0;32m     19\u001b[0m snapshot_download(repo_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistralai/Mistral-Nemo-Instruct-2407\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m     20\u001b[0m                   allow_patterns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsolidated.safetensors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtekken.json\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[0;32m     21\u001b[0m                   local_dir\u001b[38;5;241m=\u001b[39mmistral_models_path)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Load model and tokenizer\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mMistralTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmistral_models_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/tekken.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m model \u001b[38;5;241m=\u001b[39m Transformer\u001b[38;5;241m.\u001b[39mfrom_folder(mistral_models_path)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_search_phrases\u001b[39m(topic, num_phrases\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\mistral_common\\tokens\\tokenizers\\mistral.py:110\u001b[0m, in \u001b[0;36mMistralTokenizer.from_file\u001b[1;34m(cls, tokenizer_filename, mode)\u001b[0m\n\u001b[0;32m    107\u001b[0m tokenizer: Union[SentencePieceTokenizer, Tekkenizer]\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_tekken(tokenizer_filename):\n\u001b[1;32m--> 110\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mTekkenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer_filename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_sentencepiece(tokenizer_filename):\n\u001b[0;32m    112\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m SentencePieceTokenizer(tokenizer_filename)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\mistral_common\\tokens\\tokenizers\\tekken.py:130\u001b[0m, in \u001b[0;36mTekkenizer.from_file\u001b[1;34m(cls, path)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists()\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 130\u001b[0m     model_data: ModelData \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m _version_str \u001b[38;5;241m=\u001b[39m model_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _version_str \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m TokenizerVersion\u001b[38;5;241m.\u001b[39m__members__:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\json\\__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, object_hook\u001b[38;5;241m=\u001b[39mobject_hook,\n\u001b[0;32m    295\u001b[0m         parse_float\u001b[38;5;241m=\u001b[39mparse_float, parse_int\u001b[38;5;241m=\u001b[39mparse_int,\n\u001b[0;32m    296\u001b[0m         parse_constant\u001b[38;5;241m=\u001b[39mparse_constant, object_pairs_hook\u001b[38;5;241m=\u001b[39mobject_pairs_hook, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\encodings\\cp1252.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcodecs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcharmap_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdecoding_table\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x81 in position 32549: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "from mistral_inference.transformer import Transformer\n",
    "from mistral_inference.generate import generate\n",
    "from mistral_common.tokens.tokenizers.mistral import MistralTokenizer\n",
    "from mistral_common.protocol.instruct.messages import UserMessage\n",
    "from mistral_common.protocol.instruct.request import ChatCompletionRequest\n",
    "\n",
    "# Setup paths and download model\n",
    "mistral_models_path = Path.home().joinpath('mistral_models', 'Nemo-Instruct')\n",
    "mistral_models_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "snapshot_download(repo_id=\"mistralai/Mistral-Nemo-Instruct-2407\", \n",
    "                  allow_patterns=[\"params.json\", \"consolidated.safetensors\", \"tekken.json\"], \n",
    "                  local_dir=mistral_models_path)\n",
    "\n",
    "# Load model and tokenizer\n",
    "tokenizer = MistralTokenizer.from_file(f\"{mistral_models_path}/tekken.json\")\n",
    "model = Transformer.from_folder(mistral_models_path)\n",
    "\n",
    "def generate_search_phrases(topic, num_phrases=5, max_length=30):\n",
    "    \"\"\"\n",
    "    Generate search phrases based on the given topic.\n",
    "    \n",
    "    Args:\n",
    "    topic (str): The input topic.\n",
    "    num_phrases (int): Number of phrases to generate.\n",
    "    max_length (int): Maximum length of each generated phrase.\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of generated search phrases.\n",
    "    \"\"\"\n",
    "    # Define input text\n",
    "    input_text = f\"Search phrases about {topic}:\"\n",
    "    \n",
    "    # Create ChatCompletionRequest\n",
    "    completion_request = ChatCompletionRequest(messages=[UserMessage(content=input_text)])\n",
    "    \n",
    "    # Tokenize the input\n",
    "    tokens = tokenizer.encode_chat_completion(completion_request).tokens\n",
    "    \n",
    "    # Generate text\n",
    "    out_tokens, _ = generate([tokens], model, max_tokens=max_length, temperature=0.7, eos_id=tokenizer.instruct_tokenizer.tokenizer.eos_id)\n",
    "    \n",
    "    # Decode the generated tokens to form search phrases\n",
    "    search_phrases = tokenizer.decode(out_tokens[0])\n",
    "    \n",
    "    # Remove the input text from the generated phrases\n",
    "    search_phrases = search_phrases.replace(input_text, \"\").strip().split(\"\\n\")[:num_phrases]\n",
    "    \n",
    "    return search_phrases\n",
    "\n",
    "# Example usage\n",
    "topic = \"artificial intelligence\"\n",
    "generated_phrases = generate_search_phrases(topic)\n",
    "\n",
    "print(f\"Generated search phrases about {topic}:\")\n",
    "for i, phrase in enumerate(generated_phrases, 1):\n",
    "    print(f\"{i}. {phrase}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f332a893e3540bb8d63d732e64c7d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected encoding: utf-8 (confidence: 0.99)\n",
      "Error loading tokenizer: 'charmap' codec can't decode byte 0x81 in position 34446: character maps to <undefined>\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x81 in position 34446: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 51\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     48\u001b[0m         \u001b[38;5;66;03m# Remove the temporary file\u001b[39;00m\n\u001b[0;32m     49\u001b[0m         temp_file\u001b[38;5;241m.\u001b[39munlink()\n\u001b[1;32m---> 51\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mload_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmistral_models_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/tekken.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m model \u001b[38;5;241m=\u001b[39m Transformer\u001b[38;5;241m.\u001b[39mfrom_folder(mistral_models_path)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_search_phrases\u001b[39m(topic, num_phrases\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m):\n",
      "Cell \u001b[1;32mIn[3], line 42\u001b[0m, in \u001b[0;36mload_tokenizer\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     38\u001b[0m     file\u001b[38;5;241m.\u001b[39mwrite(file_content)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# Load the tokenizer from the temporary file\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mMistralTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtemp_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\mistral_common\\tokens\\tokenizers\\mistral.py:110\u001b[0m, in \u001b[0;36mMistralTokenizer.from_file\u001b[1;34m(cls, tokenizer_filename, mode)\u001b[0m\n\u001b[0;32m    107\u001b[0m tokenizer: Union[SentencePieceTokenizer, Tekkenizer]\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_tekken(tokenizer_filename):\n\u001b[1;32m--> 110\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mTekkenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer_filename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_sentencepiece(tokenizer_filename):\n\u001b[0;32m    112\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m SentencePieceTokenizer(tokenizer_filename)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\mistral_common\\tokens\\tokenizers\\tekken.py:130\u001b[0m, in \u001b[0;36mTekkenizer.from_file\u001b[1;34m(cls, path)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists()\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 130\u001b[0m     model_data: ModelData \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m _version_str \u001b[38;5;241m=\u001b[39m model_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _version_str \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m TokenizerVersion\u001b[38;5;241m.\u001b[39m__members__:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\json\\__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, object_hook\u001b[38;5;241m=\u001b[39mobject_hook,\n\u001b[0;32m    295\u001b[0m         parse_float\u001b[38;5;241m=\u001b[39mparse_float, parse_int\u001b[38;5;241m=\u001b[39mparse_int,\n\u001b[0;32m    296\u001b[0m         parse_constant\u001b[38;5;241m=\u001b[39mparse_constant, object_pairs_hook\u001b[38;5;241m=\u001b[39mobject_pairs_hook, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\encodings\\cp1252.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcodecs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcharmap_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdecoding_table\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x81 in position 34446: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import chardet\n",
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "from mistral_inference.transformer import Transformer\n",
    "from mistral_inference.generate import generate\n",
    "from mistral_common.tokens.tokenizers.mistral import MistralTokenizer\n",
    "from mistral_common.protocol.instruct.messages import UserMessage\n",
    "from mistral_common.protocol.instruct.request import ChatCompletionRequest\n",
    "\n",
    "# Setup paths and download model\n",
    "mistral_models_path = Path.home().joinpath('mistral_models', 'Nemo-Instruct')\n",
    "mistral_models_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "snapshot_download(repo_id=\"mistralai/Mistral-Nemo-Instruct-2407\", \n",
    "                  allow_patterns=[\"params.json\", \"consolidated.safetensors\", \"tekken.json\"], \n",
    "                  local_dir=mistral_models_path)\n",
    "\n",
    "def load_tokenizer(file_path):\n",
    "    # Read the file in binary mode\n",
    "    with open(file_path, 'rb') as file:\n",
    "        raw_data = file.read()\n",
    "\n",
    "    # Detect the file encoding\n",
    "    detected = chardet.detect(raw_data)\n",
    "    print(f\"Detected encoding: {detected['encoding']} (confidence: {detected['confidence']})\")\n",
    "\n",
    "    # Try decoding with the detected encoding, falling back to 'utf-8' if it fails\n",
    "    try:\n",
    "        file_content = raw_data.decode(detected['encoding'])\n",
    "    except (UnicodeDecodeError, TypeError):\n",
    "        print(f\"Failed to decode with {detected['encoding']}, falling back to utf-8\")\n",
    "        file_content = raw_data.decode('utf-8', errors='ignore')\n",
    "\n",
    "    # Create a temporary file with the decoded content\n",
    "    temp_file = Path(file_path).with_suffix('.temp.json')\n",
    "    with open(temp_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(file_content)\n",
    "\n",
    "    try:\n",
    "        # Load the tokenizer from the temporary file\n",
    "        tokenizer = MistralTokenizer.from_file(str(temp_file))\n",
    "        return tokenizer\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading tokenizer: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        # Remove the temporary file\n",
    "        temp_file.unlink()\n",
    "\n",
    "tokenizer = load_tokenizer(f\"{mistral_models_path}/tekken.json\")\n",
    "model = Transformer.from_folder(mistral_models_path)\n",
    "\n",
    "def generate_search_phrases(topic, num_phrases=5, max_length=30):\n",
    "    \"\"\"\n",
    "    Generate search phrases based on the given topic.\n",
    "    \n",
    "    Args:\n",
    "    topic (str): The input topic.\n",
    "    num_phrases (int): Number of phrases to generate.\n",
    "    max_length (int): Maximum length of each generated phrase.\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of generated search phrases.\n",
    "    \"\"\"\n",
    "    # Define input text\n",
    "    input_text = f\"Search phrases about {topic}:\"\n",
    "    \n",
    "    # Create ChatCompletionRequest\n",
    "    completion_request = ChatCompletionRequest(messages=[UserMessage(content=input_text)])\n",
    "    \n",
    "    # Tokenize the input\n",
    "    tokens = tokenizer.encode_chat_completion(completion_request).tokens\n",
    "    \n",
    "    # Generate text\n",
    "    out_tokens, _ = generate([tokens], model, max_tokens=max_length, temperature=0.7, eos_id=tokenizer.instruct_tokenizer.tokenizer.eos_id)\n",
    "    \n",
    "    # Decode the generated tokens to form search phrases\n",
    "    search_phrases = tokenizer.decode(out_tokens[0])\n",
    "    \n",
    "    # Remove the input text from the generated phrases\n",
    "    search_phrases = search_phrases.replace(input_text, \"\").strip().split(\"\\n\")[:num_phrases]\n",
    "    \n",
    "    return search_phrases\n",
    "\n",
    "# Example usage\n",
    "topic = \"artificial intelligence\"\n",
    "generated_phrases = generate_search_phrases(topic)\n",
    "print(f\"Generated search phrases about {topic}:\")\n",
    "for i, phrase in enumerate(generated_phrases, 1):\n",
    "    print(f\"{i}. {phrase}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chardet\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Using cached chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Installing collected packages: chardet\n",
      "Successfully installed chardet-5.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script chardetect.exe is installed in 'C:\\Users\\aadhi\\anaconda3\\envs\\tf\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "%pip install chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mistral_inference\n",
      "  Downloading mistral_inference-1.3.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting fire>=0.6.0 (from mistral_inference)\n",
      "  Using cached fire-0.6.0.tar.gz (88 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting mistral_common<2.0.0,>=1.3.0 (from mistral_inference)\n",
      "  Downloading mistral_common-1.3.2-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.0 in c:\\users\\aadhi\\anaconda3\\envs\\tf\\lib\\site-packages (from mistral_inference) (0.4.3)\n",
      "Collecting simple-parsing>=0.1.5 (from mistral_inference)\n",
      "  Downloading simple_parsing-0.1.5-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting xformers>=0.0.24 (from mistral_inference)\n",
      "  Downloading xformers-0.0.27-cp39-cp39-win_amd64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: six in c:\\users\\aadhi\\anaconda3\\envs\\tf\\lib\\site-packages (from fire>=0.6.0->mistral_inference) (1.16.0)\n",
      "Requirement already satisfied: termcolor in c:\\users\\aadhi\\anaconda3\\envs\\tf\\lib\\site-packages (from fire>=0.6.0->mistral_inference) (2.4.0)\n",
      "Collecting jsonschema==4.21.1 (from mistral_common<2.0.0,>=1.3.0->mistral_inference)\n",
      "  Downloading jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting pydantic==2.6.1 (from mistral_common<2.0.0,>=1.3.0->mistral_inference)\n",
      "  Downloading pydantic-2.6.1-py3-none-any.whl.metadata (83 kB)\n",
      "     ---------------------------------------- 0.0/83.5 kB ? eta -:--:--\n",
      "     -------------- ------------------------- 30.7/83.5 kB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 83.5/83.5 kB 1.6 MB/s eta 0:00:00\n",
      "Collecting sentencepiece==0.2.0 (from mistral_common<2.0.0,>=1.3.0->mistral_inference)\n",
      "  Using cached sentencepiece-0.2.0-cp39-cp39-win_amd64.whl.metadata (8.3 kB)\n",
      "Collecting tiktoken<0.8.0,>=0.7.0 (from mistral_common<2.0.0,>=1.3.0->mistral_inference)\n",
      "  Using cached tiktoken-0.7.0-cp39-cp39-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in c:\\users\\aadhi\\anaconda3\\envs\\tf\\lib\\site-packages (from mistral_common<2.0.0,>=1.3.0->mistral_inference) (4.11.0)\n",
      "Collecting attrs>=22.2.0 (from jsonschema==4.21.1->mistral_common<2.0.0,>=1.3.0->mistral_inference)\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema==4.21.1->mistral_common<2.0.0,>=1.3.0->mistral_inference)\n",
      "  Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema==4.21.1->mistral_common<2.0.0,>=1.3.0->mistral_inference)\n",
      "  Using cached referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema==4.21.1->mistral_common<2.0.0,>=1.3.0->mistral_inference)\n",
      "  Downloading rpds_py-0.19.0-cp39-none-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic==2.6.1->mistral_common<2.0.0,>=1.3.0->mistral_inference)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.16.2 (from pydantic==2.6.1->mistral_common<2.0.0,>=1.3.0->mistral_inference)\n",
      "  Downloading pydantic_core-2.16.2-cp39-none-win_amd64.whl.metadata (6.6 kB)\n",
      "Collecting docstring-parser~=0.15 (from simple-parsing>=0.1.5->mistral_inference)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\aadhi\\anaconda3\\envs\\tf\\lib\\site-packages (from xformers>=0.0.24->mistral_inference) (1.21.5)\n",
      "Collecting torch==2.3.1 (from xformers>=0.0.24->mistral_inference)\n",
      "  Using cached torch-2.3.1-cp39-cp39-win_amd64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\aadhi\\anaconda3\\envs\\tf\\lib\\site-packages (from torch==2.3.1->xformers>=0.0.24->mistral_inference) (3.15.4)\n",
      "Collecting sympy (from torch==2.3.1->xformers>=0.0.24->mistral_inference)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch==2.3.1->xformers>=0.0.24->mistral_inference)\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting jinja2 (from torch==2.3.1->xformers>=0.0.24->mistral_inference)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\aadhi\\anaconda3\\envs\\tf\\lib\\site-packages (from torch==2.3.1->xformers>=0.0.24->mistral_inference) (2024.6.1)\n",
      "Collecting mkl<=2021.4.0,>=2021.1.1 (from torch==2.3.1->xformers>=0.0.24->mistral_inference)\n",
      "  Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\aadhi\\anaconda3\\envs\\tf\\lib\\site-packages (from tiktoken<0.8.0,>=0.7.0->mistral_common<2.0.0,>=1.3.0->mistral_inference) (2024.5.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\aadhi\\anaconda3\\envs\\tf\\lib\\site-packages (from tiktoken<0.8.0,>=0.7.0->mistral_common<2.0.0,>=1.3.0->mistral_inference) (2.32.3)\n",
      "Collecting intel-openmp==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.1->xformers>=0.0.24->mistral_inference)\n",
      "  Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting tbb==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.1->xformers>=0.0.24->mistral_inference)\n",
      "  Using cached tbb-2021.13.0-py3-none-win_amd64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aadhi\\anaconda3\\envs\\tf\\lib\\site-packages (from requests>=2.26.0->tiktoken<0.8.0,>=0.7.0->mistral_common<2.0.0,>=1.3.0->mistral_inference) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aadhi\\anaconda3\\envs\\tf\\lib\\site-packages (from requests>=2.26.0->tiktoken<0.8.0,>=0.7.0->mistral_common<2.0.0,>=1.3.0->mistral_inference) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aadhi\\anaconda3\\envs\\tf\\lib\\site-packages (from requests>=2.26.0->tiktoken<0.8.0,>=0.7.0->mistral_common<2.0.0,>=1.3.0->mistral_inference) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aadhi\\anaconda3\\envs\\tf\\lib\\site-packages (from requests>=2.26.0->tiktoken<0.8.0,>=0.7.0->mistral_common<2.0.0,>=1.3.0->mistral_inference) (2024.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aadhi\\anaconda3\\envs\\tf\\lib\\site-packages (from jinja2->torch==2.3.1->xformers>=0.0.24->mistral_inference) (2.1.5)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.3.1->xformers>=0.0.24->mistral_inference)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading mistral_inference-1.3.0-py3-none-any.whl (25 kB)\n",
      "Downloading mistral_common-1.3.2-py3-none-any.whl (3.3 MB)\n",
      "   ---------------------------------------- 0.0/3.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/3.3 MB 3.6 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.3/3.3 MB 5.3 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.7/3.3 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 1.0/3.3 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 1.0/3.3 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 1.0/3.3 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 1.0/3.3 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.1/3.3 MB 3.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.7/3.3 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 2.1/3.3 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 2.1/3.3 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 2.1/3.3 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 2.1/3.3 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 2.1/3.3 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.5/3.3 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 3.1/3.3 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 3.1/3.3 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 3.1/3.3 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.3/3.3 MB 3.9 MB/s eta 0:00:00\n",
      "Downloading jsonschema-4.21.1-py3-none-any.whl (85 kB)\n",
      "   ---------------------------------------- 0.0/85.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 85.5/85.5 kB 4.7 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.6.1-py3-none-any.whl (394 kB)\n",
      "   ---------------------------------------- 0.0/394.8 kB ? eta -:--:--\n",
      "   ---------------------------------- ----- 337.9/394.8 kB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 394.8/394.8 kB 6.1 MB/s eta 0:00:00\n",
      "Using cached sentencepiece-0.2.0-cp39-cp39-win_amd64.whl (991 kB)\n",
      "Downloading pydantic_core-2.16.2-cp39-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.2/1.9 MB 12.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.8/1.9 MB 10.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.0/1.9 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.0/1.9 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.0/1.9 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.0/1.9 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.0/1.9 MB 11.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.2/1.9 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 4.6 MB/s eta 0:00:00\n",
      "Downloading simple_parsing-0.1.5-py3-none-any.whl (113 kB)\n",
      "   ---------------------------------------- 0.0/113.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 113.6/113.6 kB 6.9 MB/s eta 0:00:00\n",
      "Downloading xformers-0.0.27-cp39-cp39-win_amd64.whl (152.1 MB)\n",
      "   ---------------------------------------- 0.0/152.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/152.1 MB 9.6 MB/s eta 0:00:16\n",
      "   ---------------------------------------- 0.9/152.1 MB 11.9 MB/s eta 0:00:13\n",
      "   ---------------------------------------- 1.0/152.1 MB 13.3 MB/s eta 0:00:12\n",
      "   ---------------------------------------- 1.0/152.1 MB 13.3 MB/s eta 0:00:12\n",
      "   ---------------------------------------- 1.0/152.1 MB 13.3 MB/s eta 0:00:12\n",
      "   ---------------------------------------- 1.0/152.1 MB 13.3 MB/s eta 0:00:12\n",
      "   ---------------------------------------- 1.0/152.1 MB 13.3 MB/s eta 0:00:12\n",
      "   ---------------------------------------- 1.0/152.1 MB 13.3 MB/s eta 0:00:12\n",
      "   ---------------------------------------- 1.0/152.1 MB 13.3 MB/s eta 0:00:12\n",
      "   ---------------------------------------- 1.0/152.1 MB 13.3 MB/s eta 0:00:12\n",
      "   ---------------------------------------- 1.3/152.1 MB 2.6 MB/s eta 0:00:58\n",
      "    --------------------------------------- 1.9/152.1 MB 3.5 MB/s eta 0:00:43\n",
      "    --------------------------------------- 2.1/152.1 MB 3.8 MB/s eta 0:00:40\n",
      "    --------------------------------------- 2.1/152.1 MB 3.8 MB/s eta 0:00:40\n",
      "    --------------------------------------- 2.1/152.1 MB 3.8 MB/s eta 0:00:40\n",
      "    --------------------------------------- 2.4/152.1 MB 3.2 MB/s eta 0:00:47\n",
      "    --------------------------------------- 2.8/152.1 MB 3.7 MB/s eta 0:00:41\n",
      "    --------------------------------------- 3.0/152.1 MB 3.7 MB/s eta 0:00:40\n",
      "    --------------------------------------- 3.1/152.1 MB 3.7 MB/s eta 0:00:41\n",
      "    --------------------------------------- 3.3/152.1 MB 3.6 MB/s eta 0:00:42\n",
      "    --------------------------------------- 3.5/152.1 MB 3.7 MB/s eta 0:00:41\n",
      "    --------------------------------------- 3.6/152.1 MB 3.6 MB/s eta 0:00:42\n",
      "    --------------------------------------- 3.7/152.1 MB 3.6 MB/s eta 0:00:42\n",
      "   - -------------------------------------- 4.0/152.1 MB 3.6 MB/s eta 0:00:42\n",
      "   - -------------------------------------- 4.3/152.1 MB 3.8 MB/s eta 0:00:40\n",
      "   - -------------------------------------- 4.4/152.1 MB 3.7 MB/s eta 0:00:40\n",
      "   - -------------------------------------- 4.6/152.1 MB 3.7 MB/s eta 0:00:40\n",
      "   - -------------------------------------- 4.9/152.1 MB 3.8 MB/s eta 0:00:39\n",
      "   - -------------------------------------- 5.1/152.1 MB 3.9 MB/s eta 0:00:38\n",
      "   - -------------------------------------- 5.2/152.1 MB 3.8 MB/s eta 0:00:39\n",
      "   - -------------------------------------- 5.3/152.1 MB 3.7 MB/s eta 0:00:40\n",
      "   - -------------------------------------- 5.5/152.1 MB 3.8 MB/s eta 0:00:39\n",
      "   - -------------------------------------- 5.6/152.1 MB 3.7 MB/s eta 0:00:40\n",
      "   - -------------------------------------- 5.7/152.1 MB 3.7 MB/s eta 0:00:40\n",
      "   - -------------------------------------- 5.8/152.1 MB 3.6 MB/s eta 0:00:41\n",
      "   - -------------------------------------- 6.1/152.1 MB 3.7 MB/s eta 0:00:40\n",
      "   - -------------------------------------- 6.1/152.1 MB 3.6 MB/s eta 0:00:41\n",
      "   - -------------------------------------- 6.1/152.1 MB 3.5 MB/s eta 0:00:42\n",
      "   - -------------------------------------- 6.4/152.1 MB 3.6 MB/s eta 0:00:41\n",
      "   - -------------------------------------- 6.9/152.1 MB 3.7 MB/s eta 0:00:39\n",
      "   - -------------------------------------- 7.2/152.1 MB 3.8 MB/s eta 0:00:39\n",
      "   - -------------------------------------- 7.4/152.1 MB 3.8 MB/s eta 0:00:38\n",
      "   - -------------------------------------- 7.6/152.1 MB 3.8 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 7.8/152.1 MB 3.9 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 8.0/152.1 MB 3.9 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 8.3/152.1 MB 3.9 MB/s eta 0:00:37\n",
      "   -- ------------------------------------- 8.8/152.1 MB 4.1 MB/s eta 0:00:36\n",
      "   -- ------------------------------------- 9.3/152.1 MB 4.2 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 9.8/152.1 MB 4.3 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 10.0/152.1 MB 4.3 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 10.4/152.1 MB 4.4 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 10.5/152.1 MB 4.4 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 10.5/152.1 MB 4.4 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 10.8/152.1 MB 4.2 MB/s eta 0:00:34\n",
      "   --- ------------------------------------ 11.5/152.1 MB 5.0 MB/s eta 0:00:29\n",
      "   --- ------------------------------------ 11.5/152.1 MB 5.0 MB/s eta 0:00:29\n",
      "   --- ------------------------------------ 11.5/152.1 MB 5.0 MB/s eta 0:00:29\n",
      "   --- ------------------------------------ 11.5/152.1 MB 5.0 MB/s eta 0:00:29\n",
      "   --- ------------------------------------ 12.0/152.1 MB 4.7 MB/s eta 0:00:30\n",
      "   --- ------------------------------------ 12.1/152.1 MB 4.6 MB/s eta 0:00:31\n",
      "   --- ------------------------------------ 12.3/152.1 MB 4.5 MB/s eta 0:00:31\n",
      "   --- ------------------------------------ 12.7/152.1 MB 4.8 MB/s eta 0:00:29\n",
      "   --- ------------------------------------ 13.0/152.1 MB 4.8 MB/s eta 0:00:30\n",
      "   --- ------------------------------------ 13.2/152.1 MB 4.7 MB/s eta 0:00:30\n",
      "   --- ------------------------------------ 13.3/152.1 MB 4.7 MB/s eta 0:00:30\n",
      "   --- ------------------------------------ 13.5/152.1 MB 4.8 MB/s eta 0:00:30\n",
      "   --- ------------------------------------ 13.6/152.1 MB 4.7 MB/s eta 0:00:30\n",
      "   --- ------------------------------------ 13.9/152.1 MB 4.9 MB/s eta 0:00:29\n",
      "   --- ------------------------------------ 14.3/152.1 MB 4.9 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 14.7/152.1 MB 5.0 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 15.0/152.1 MB 5.1 MB/s eta 0:00:27\n",
      "   ---- ----------------------------------- 15.4/152.1 MB 5.2 MB/s eta 0:00:27\n",
      "   ---- ----------------------------------- 15.7/152.1 MB 5.4 MB/s eta 0:00:26\n",
      "   ---- ----------------------------------- 16.1/152.1 MB 5.7 MB/s eta 0:00:24\n",
      "   ---- ----------------------------------- 16.3/152.1 MB 5.8 MB/s eta 0:00:24\n",
      "   ---- ----------------------------------- 16.7/152.1 MB 6.0 MB/s eta 0:00:23\n",
      "   ---- ----------------------------------- 16.8/152.1 MB 6.0 MB/s eta 0:00:23\n",
      "   ---- ----------------------------------- 16.8/152.1 MB 6.0 MB/s eta 0:00:23\n",
      "   ---- ----------------------------------- 16.8/152.1 MB 6.0 MB/s eta 0:00:23\n",
      "   ---- ----------------------------------- 16.8/152.1 MB 6.0 MB/s eta 0:00:23\n",
      "   ---- ----------------------------------- 16.8/152.1 MB 6.0 MB/s eta 0:00:23\n",
      "   ---- ----------------------------------- 17.1/152.1 MB 5.2 MB/s eta 0:00:26\n",
      "   ---- ----------------------------------- 17.5/152.1 MB 5.4 MB/s eta 0:00:26\n",
      "   ---- ----------------------------------- 17.9/152.1 MB 5.4 MB/s eta 0:00:25\n",
      "   ---- ----------------------------------- 18.2/152.1 MB 5.5 MB/s eta 0:00:25\n",
      "   ---- ----------------------------------- 18.7/152.1 MB 5.5 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 19.1/152.1 MB 5.6 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 19.5/152.1 MB 5.5 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 19.8/152.1 MB 5.5 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 19.9/152.1 MB 5.5 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 19.9/152.1 MB 5.5 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 19.9/152.1 MB 5.5 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 19.9/152.1 MB 5.0 MB/s eta 0:00:27\n",
      "   ----- ---------------------------------- 20.4/152.1 MB 5.1 MB/s eta 0:00:26\n",
      "   ----- ---------------------------------- 20.8/152.1 MB 5.3 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 21.2/152.1 MB 5.3 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 21.7/152.1 MB 5.2 MB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 22.0/152.1 MB 5.6 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 22.0/152.1 MB 5.6 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 22.0/152.1 MB 5.6 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 22.0/152.1 MB 5.6 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 22.0/152.1 MB 5.6 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 22.0/152.1 MB 5.6 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 22.0/152.1 MB 5.6 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 22.0/152.1 MB 5.6 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 22.0/152.1 MB 5.6 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 22.0/152.1 MB 5.6 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 22.0/152.1 MB 5.6 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 22.0/152.1 MB 5.6 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 22.0/152.1 MB 5.6 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 22.1/152.1 MB 4.2 MB/s eta 0:00:31\n",
      "   ----- ---------------------------------- 22.4/152.1 MB 4.3 MB/s eta 0:00:31\n",
      "   ------ --------------------------------- 22.8/152.1 MB 4.3 MB/s eta 0:00:31\n",
      "   ------ --------------------------------- 23.3/152.1 MB 4.3 MB/s eta 0:00:30\n",
      "   ------ --------------------------------- 23.7/152.1 MB 4.5 MB/s eta 0:00:29\n",
      "   ------ --------------------------------- 24.1/152.1 MB 4.6 MB/s eta 0:00:28\n",
      "   ------ --------------------------------- 24.3/152.1 MB 4.6 MB/s eta 0:00:28\n",
      "   ------ --------------------------------- 24.5/152.1 MB 4.5 MB/s eta 0:00:29\n",
      "   ------ --------------------------------- 24.8/152.1 MB 4.5 MB/s eta 0:00:29\n",
      "   ------ --------------------------------- 25.0/152.1 MB 4.5 MB/s eta 0:00:29\n",
      "   ------ --------------------------------- 25.2/152.1 MB 4.4 MB/s eta 0:00:29\n",
      "   ------ --------------------------------- 25.2/152.1 MB 4.4 MB/s eta 0:00:29\n",
      "   ------ --------------------------------- 25.3/152.1 MB 4.3 MB/s eta 0:00:30\n",
      "   ------ --------------------------------- 25.5/152.1 MB 4.2 MB/s eta 0:00:30\n",
      "   ------ --------------------------------- 26.1/152.1 MB 4.3 MB/s eta 0:00:30\n",
      "   ------ --------------------------------- 26.2/152.1 MB 4.3 MB/s eta 0:00:30\n",
      "   ------ --------------------------------- 26.2/152.1 MB 4.3 MB/s eta 0:00:30\n",
      "   ------ --------------------------------- 26.2/152.1 MB 4.3 MB/s eta 0:00:30\n",
      "   ------ --------------------------------- 26.2/152.1 MB 4.3 MB/s eta 0:00:30\n",
      "   ------ --------------------------------- 26.6/152.1 MB 4.0 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 27.0/152.1 MB 4.0 MB/s eta 0:00:31\n",
      "   ------- -------------------------------- 27.3/152.1 MB 4.5 MB/s eta 0:00:29\n",
      "   ------- -------------------------------- 27.3/152.1 MB 4.5 MB/s eta 0:00:29\n",
      "   ------- -------------------------------- 27.3/152.1 MB 4.5 MB/s eta 0:00:29\n",
      "   ------- -------------------------------- 27.3/152.1 MB 4.5 MB/s eta 0:00:29\n",
      "   ------- -------------------------------- 27.3/152.1 MB 4.5 MB/s eta 0:00:29\n",
      "   ------- -------------------------------- 27.3/152.1 MB 4.5 MB/s eta 0:00:29\n",
      "   ------- -------------------------------- 27.3/152.1 MB 4.5 MB/s eta 0:00:29\n",
      "   ------- -------------------------------- 27.3/152.1 MB 4.5 MB/s eta 0:00:29\n",
      "   ------- -------------------------------- 27.3/152.1 MB 4.5 MB/s eta 0:00:29\n",
      "   ------- -------------------------------- 27.3/152.1 MB 4.5 MB/s eta 0:00:29\n",
      "   ------- -------------------------------- 27.3/152.1 MB 4.5 MB/s eta 0:00:29\n",
      "   ------- -------------------------------- 27.3/152.1 MB 4.5 MB/s eta 0:00:29\n",
      "   ------- -------------------------------- 27.3/152.1 MB 4.5 MB/s eta 0:00:29\n",
      "   ------- -------------------------------- 27.3/152.1 MB 4.5 MB/s eta 0:00:29\n",
      "   ------- -------------------------------- 27.3/152.1 MB 3.4 MB/s eta 0:00:37\n",
      "   ------- -------------------------------- 28.0/152.1 MB 3.5 MB/s eta 0:00:36\n",
      "   ------- -------------------------------- 28.4/152.1 MB 3.5 MB/s eta 0:00:36\n",
      "   ------- -------------------------------- 29.0/152.1 MB 3.5 MB/s eta 0:00:36\n",
      "   ------- -------------------------------- 29.5/152.1 MB 3.5 MB/s eta 0:00:35\n",
      "   ------- -------------------------------- 30.0/152.1 MB 3.6 MB/s eta 0:00:35\n",
      "   -------- ------------------------------- 30.6/152.1 MB 3.8 MB/s eta 0:00:33\n",
      "   -------- ------------------------------- 31.1/152.1 MB 3.8 MB/s eta 0:00:32\n",
      "   -------- ------------------------------- 31.3/152.1 MB 3.8 MB/s eta 0:00:32\n",
      "   -------- ------------------------------- 31.9/152.1 MB 3.8 MB/s eta 0:00:32\n",
      "   -------- ------------------------------- 32.4/152.1 MB 4.9 MB/s eta 0:00:25\n",
      "   -------- ------------------------------- 32.9/152.1 MB 5.0 MB/s eta 0:00:25\n",
      "   -------- ------------------------------- 33.4/152.1 MB 5.0 MB/s eta 0:00:24\n",
      "   -------- ------------------------------- 34.1/152.1 MB 5.0 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 34.7/152.1 MB 5.2 MB/s eta 0:00:23\n",
      "   --------- ------------------------------ 35.3/152.1 MB 5.5 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 35.8/152.1 MB 5.8 MB/s eta 0:00:20\n",
      "   --------- ------------------------------ 36.2/152.1 MB 5.7 MB/s eta 0:00:21\n",
      "   --------- ------------------------------ 36.7/152.1 MB 6.5 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 37.2/152.1 MB 6.5 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 37.7/152.1 MB 11.3 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 38.1/152.1 MB 10.9 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 38.5/152.1 MB 10.9 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 38.9/152.1 MB 10.7 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 39.3/152.1 MB 10.6 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 39.6/152.1 MB 10.6 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 40.0/152.1 MB 10.2 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 40.5/152.1 MB 10.2 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 41.1/152.1 MB 10.2 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 41.6/152.1 MB 10.7 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 42.0/152.1 MB 10.6 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 42.5/152.1 MB 10.4 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 43.0/152.1 MB 10.6 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 43.6/152.1 MB 10.6 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 44.2/152.1 MB 10.6 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 44.8/152.1 MB 10.6 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 45.1/152.1 MB 10.2 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 45.2/152.1 MB 10.2 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 45.2/152.1 MB 10.2 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 45.3/152.1 MB 9.1 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 45.8/152.1 MB 9.1 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 46.4/152.1 MB 9.1 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 46.6/152.1 MB 9.0 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 47.0/152.1 MB 9.0 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 47.4/152.1 MB 8.8 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 47.5/152.1 MB 8.7 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 47.7/152.1 MB 8.4 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 48.1/152.1 MB 8.3 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 48.4/152.1 MB 8.2 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 49.0/152.1 MB 8.4 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 49.5/152.1 MB 8.6 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 50.0/152.1 MB 8.7 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 50.3/152.1 MB 8.6 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 50.4/152.1 MB 8.5 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 50.6/152.1 MB 8.2 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 51.1/152.1 MB 8.1 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 51.5/152.1 MB 8.1 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 52.1/152.1 MB 8.2 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 52.4/152.1 MB 8.1 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 52.8/152.1 MB 8.0 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 53.3/152.1 MB 8.0 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 53.7/152.1 MB 7.9 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 54.2/152.1 MB 7.9 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 54.7/152.1 MB 7.8 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 55.2/152.1 MB 7.8 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 55.7/152.1 MB 8.6 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 56.0/152.1 MB 8.5 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 56.6/152.1 MB 8.5 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 56.6/152.1 MB 8.5 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 56.6/152.1 MB 8.5 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 56.6/152.1 MB 8.5 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 56.6/152.1 MB 8.5 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 56.6/152.1 MB 8.5 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 56.6/152.1 MB 8.5 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 56.6/152.1 MB 8.5 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 56.6/152.1 MB 8.5 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 56.6/152.1 MB 8.5 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 56.6/152.1 MB 8.5 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 56.6/152.1 MB 8.5 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 56.6/152.1 MB 8.5 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 56.6/152.1 MB 8.5 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 56.7/152.1 MB 5.6 MB/s eta 0:00:18\n",
      "   -------------- ------------------------- 57.0/152.1 MB 5.5 MB/s eta 0:00:18\n",
      "   --------------- ------------------------ 57.5/152.1 MB 5.6 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 57.7/152.1 MB 5.6 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 57.7/152.1 MB 5.6 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 58.0/152.1 MB 5.5 MB/s eta 0:00:18\n",
      "   --------------- ------------------------ 58.6/152.1 MB 5.6 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 58.7/152.1 MB 5.6 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 58.7/152.1 MB 5.6 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 58.7/152.1 MB 5.6 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 58.7/152.1 MB 5.2 MB/s eta 0:00:19\n",
      "   --------------- ------------------------ 59.3/152.1 MB 5.2 MB/s eta 0:00:18\n",
      "   --------------- ------------------------ 59.6/152.1 MB 5.1 MB/s eta 0:00:19\n",
      "   --------------- ------------------------ 59.8/152.1 MB 5.0 MB/s eta 0:00:19\n",
      "   --------------- ------------------------ 59.8/152.1 MB 5.0 MB/s eta 0:00:19\n",
      "   --------------- ------------------------ 59.8/152.1 MB 5.0 MB/s eta 0:00:19\n",
      "   --------------- ------------------------ 60.2/152.1 MB 4.8 MB/s eta 0:00:20\n",
      "   --------------- ------------------------ 60.8/152.1 MB 5.0 MB/s eta 0:00:19\n",
      "   --------------- ------------------------ 60.8/152.1 MB 5.0 MB/s eta 0:00:19\n",
      "   --------------- ------------------------ 60.8/152.1 MB 5.0 MB/s eta 0:00:19\n",
      "   --------------- ------------------------ 60.8/152.1 MB 5.0 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 60.9/152.1 MB 4.6 MB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 61.6/152.1 MB 4.6 MB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 61.9/152.1 MB 4.6 MB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 61.9/152.1 MB 4.6 MB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 61.9/152.1 MB 4.6 MB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 61.9/152.1 MB 4.6 MB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 61.9/152.1 MB 4.6 MB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 62.2/152.1 MB 4.2 MB/s eta 0:00:22\n",
      "   ---------------- ----------------------- 62.5/152.1 MB 4.2 MB/s eta 0:00:22\n",
      "   ---------------- ----------------------- 63.1/152.1 MB 4.2 MB/s eta 0:00:22\n",
      "   ---------------- ----------------------- 63.6/152.1 MB 4.2 MB/s eta 0:00:21\n",
      "   ---------------- ----------------------- 64.0/152.1 MB 4.2 MB/s eta 0:00:21\n",
      "   ---------------- ----------------------- 64.4/152.1 MB 4.2 MB/s eta 0:00:21\n",
      "   ----------------- ---------------------- 65.0/152.1 MB 4.3 MB/s eta 0:00:21\n",
      "   ----------------- ---------------------- 65.5/152.1 MB 4.3 MB/s eta 0:00:21\n",
      "   ----------------- ---------------------- 65.9/152.1 MB 4.2 MB/s eta 0:00:21\n",
      "   ----------------- ---------------------- 66.6/152.1 MB 4.3 MB/s eta 0:00:20\n",
      "   ----------------- ---------------------- 67.0/152.1 MB 5.8 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 67.7/152.1 MB 6.0 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 68.4/152.1 MB 6.4 MB/s eta 0:00:14\n",
      "   ------------------ --------------------- 68.9/152.1 MB 6.4 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 69.6/152.1 MB 7.2 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 70.0/152.1 MB 7.4 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 70.6/152.1 MB 8.0 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 71.1/152.1 MB 9.2 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 71.3/152.1 MB 9.2 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 71.3/152.1 MB 9.2 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 71.3/152.1 MB 9.2 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 71.3/152.1 MB 9.2 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 71.3/152.1 MB 9.2 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 71.3/152.1 MB 9.2 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 71.3/152.1 MB 9.2 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 71.3/152.1 MB 9.2 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 71.3/152.1 MB 9.2 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 71.3/152.1 MB 9.2 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 71.3/152.1 MB 9.2 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 71.3/152.1 MB 6.3 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 71.3/152.1 MB 6.1 MB/s eta 0:00:14\n",
      "   ------------------ --------------------- 71.4/152.1 MB 6.0 MB/s eta 0:00:14\n",
      "   ------------------ --------------------- 71.4/152.1 MB 5.9 MB/s eta 0:00:14\n",
      "   ------------------ --------------------- 71.6/152.1 MB 5.6 MB/s eta 0:00:15\n",
      "   ------------------ --------------------- 71.9/152.1 MB 5.5 MB/s eta 0:00:15\n",
      "   ------------------ --------------------- 72.2/152.1 MB 6.2 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 72.2/152.1 MB 6.2 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 72.2/152.1 MB 6.2 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 72.6/152.1 MB 6.0 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 73.0/152.1 MB 5.9 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 73.6/152.1 MB 5.9 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 74.0/152.1 MB 6.0 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 74.4/152.1 MB 5.9 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 74.8/152.1 MB 5.9 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 75.3/152.1 MB 5.8 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 75.8/152.1 MB 5.8 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 76.3/152.1 MB 5.9 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 77.1/152.1 MB 5.9 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 77.6/152.1 MB 5.9 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 77.8/152.1 MB 5.8 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 78.2/152.1 MB 5.7 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 78.7/152.1 MB 5.7 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 79.1/152.1 MB 5.6 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 79.4/152.1 MB 5.5 MB/s eta 0:00:14\n",
      "   --------------------- ------------------ 79.9/152.1 MB 5.5 MB/s eta 0:00:14\n",
      "   --------------------- ------------------ 80.4/152.1 MB 5.5 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 80.9/152.1 MB 5.6 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 81.4/152.1 MB 5.6 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 82.0/152.1 MB 9.0 MB/s eta 0:00:08\n",
      "   --------------------- ------------------ 82.5/152.1 MB 10.2 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 83.0/152.1 MB 10.2 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 83.4/152.1 MB 10.1 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 83.8/152.1 MB 9.9 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 83.9/152.1 MB 9.9 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 84.4/152.1 MB 9.8 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 84.9/152.1 MB 9.9 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 85.4/152.1 MB 9.9 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 85.9/152.1 MB 9.9 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 86.5/152.1 MB 9.9 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 86.9/152.1 MB 9.8 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 87.2/152.1 MB 9.5 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 87.8/152.1 MB 9.5 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 88.4/152.1 MB 10.1 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 88.8/152.1 MB 9.9 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 89.6/152.1 MB 10.6 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 90.2/152.1 MB 10.6 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 90.2/152.1 MB 10.4 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 90.2/152.1 MB 10.4 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 90.2/152.1 MB 10.4 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 90.2/152.1 MB 10.4 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 90.2/152.1 MB 10.4 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 90.2/152.1 MB 10.4 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 90.2/152.1 MB 10.4 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 90.2/152.1 MB 10.4 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 90.2/152.1 MB 10.4 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 90.2/152.1 MB 10.4 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 90.2/152.1 MB 10.4 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 90.2/152.1 MB 10.4 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 90.2/152.1 MB 6.5 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 90.4/152.1 MB 6.4 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 90.7/152.1 MB 6.4 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 91.1/152.1 MB 6.3 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 91.2/152.1 MB 6.3 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 91.4/152.1 MB 6.0 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 91.9/152.1 MB 6.0 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 92.4/152.1 MB 6.0 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 92.9/152.1 MB 6.0 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 93.4/152.1 MB 6.0 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 93.9/152.1 MB 6.1 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 94.4/152.1 MB 6.2 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 94.9/152.1 MB 6.2 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 95.4/152.1 MB 6.2 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 95.9/152.1 MB 6.2 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 96.4/152.1 MB 6.2 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 96.9/152.1 MB 6.2 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 97.4/152.1 MB 6.4 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 98.0/152.1 MB 6.3 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 98.5/152.1 MB 6.3 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 98.6/152.1 MB 6.2 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 98.6/152.1 MB 6.2 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 98.6/152.1 MB 6.2 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 98.6/152.1 MB 6.2 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 98.6/152.1 MB 6.2 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 98.6/152.1 MB 6.2 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 98.6/152.1 MB 6.2 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 98.6/152.1 MB 6.2 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 98.6/152.1 MB 6.2 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 98.6/152.1 MB 6.2 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 98.6/152.1 MB 4.8 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 98.8/152.1 MB 4.8 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 99.0/152.1 MB 4.7 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 99.0/152.1 MB 4.6 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 99.0/152.1 MB 4.6 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 99.6/152.1 MB 4.5 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 99.8/152.1 MB 4.4 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 100.3/152.1 MB 4.4 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 100.9/152.1 MB 6.1 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 101.4/152.1 MB 6.1 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 101.7/152.1 MB 6.4 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 101.7/152.1 MB 6.4 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 101.7/152.1 MB 6.4 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 101.7/152.1 MB 6.4 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 101.7/152.1 MB 6.4 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 102.1/152.1 MB 5.7 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 102.6/152.1 MB 5.7 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 103.2/152.1 MB 5.7 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 103.7/152.1 MB 5.7 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 103.8/152.1 MB 5.7 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 104.2/152.1 MB 5.6 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 104.5/152.1 MB 5.5 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 104.9/152.1 MB 5.5 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 104.9/152.1 MB 5.5 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 104.9/152.1 MB 5.5 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 104.9/152.1 MB 5.5 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 105.0/152.1 MB 5.0 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 105.4/152.1 MB 5.0 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 105.9/152.1 MB 5.0 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 105.9/152.1 MB 5.0 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 105.9/152.1 MB 5.0 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 105.9/152.1 MB 5.0 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 106.0/152.1 MB 4.6 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 106.6/152.1 MB 4.6 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 106.9/152.1 MB 4.6 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 106.9/152.1 MB 4.6 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 106.9/152.1 MB 4.6 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 107.0/152.1 MB 4.3 MB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 107.5/152.1 MB 4.3 MB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 108.0/152.1 MB 4.3 MB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 108.5/152.1 MB 4.3 MB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 109.0/152.1 MB 5.5 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 109.0/152.1 MB 5.5 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 109.0/152.1 MB 5.5 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 109.0/152.1 MB 5.5 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 109.0/152.1 MB 5.5 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 109.0/152.1 MB 5.5 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 109.0/152.1 MB 5.5 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 109.0/152.1 MB 5.5 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 109.1/152.1 MB 4.6 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 109.5/152.1 MB 4.9 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 110.0/152.1 MB 4.9 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 110.6/152.1 MB 4.9 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 111.2/152.1 MB 5.0 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 111.8/152.1 MB 5.0 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 112.4/152.1 MB 5.6 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 113.1/152.1 MB 5.6 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 113.2/152.1 MB 5.5 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 113.2/152.1 MB 5.5 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 113.2/152.1 MB 5.5 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 113.2/152.1 MB 5.5 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 113.3/152.1 MB 5.0 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 113.7/152.1 MB 5.0 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 114.2/152.1 MB 5.1 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 114.8/152.1 MB 5.2 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 115.5/152.1 MB 5.8 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 116.1/152.1 MB 5.8 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 116.8/152.1 MB 6.5 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 117.4/152.1 MB 7.2 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 117.4/152.1 MB 7.2 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 117.4/152.1 MB 7.2 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 117.6/152.1 MB 6.7 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 118.2/152.1 MB 6.7 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 118.5/152.1 MB 6.7 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 118.5/152.1 MB 6.6 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 118.5/152.1 MB 6.6 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 118.5/152.1 MB 6.6 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 118.8/152.1 MB 6.1 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 119.4/152.1 MB 7.8 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 120.1/152.1 MB 7.9 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 120.6/152.1 MB 8.0 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 120.6/152.1 MB 8.0 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 120.6/152.1 MB 8.0 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 120.9/152.1 MB 7.2 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 121.3/152.1 MB 7.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 121.7/152.1 MB 7.0 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 122.1/152.1 MB 7.0 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 122.6/152.1 MB 6.9 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 123.0/152.1 MB 6.8 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 123.6/152.1 MB 8.0 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 124.2/152.1 MB 8.2 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 124.9/152.1 MB 8.3 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 125.5/152.1 MB 8.1 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 126.1/152.1 MB 8.1 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 126.6/152.1 MB 8.0 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 126.8/152.1 MB 7.9 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 126.9/152.1 MB 7.8 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 126.9/152.1 MB 7.8 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 126.9/152.1 MB 7.8 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 127.2/152.1 MB 7.0 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 127.5/152.1 MB 7.0 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 127.9/152.1 MB 7.6 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 127.9/152.1 MB 7.5 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 127.9/152.1 MB 7.5 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 127.9/152.1 MB 7.5 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 127.9/152.1 MB 7.5 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 128.2/152.1 MB 6.5 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 128.7/152.1 MB 6.5 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 129.1/152.1 MB 7.2 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 129.6/152.1 MB 7.1 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 130.0/152.1 MB 7.1 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 130.0/152.1 MB 7.1 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 130.2/152.1 MB 6.7 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 130.5/152.1 MB 6.6 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 130.9/152.1 MB 7.1 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 131.4/152.1 MB 7.1 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 131.9/152.1 MB 7.2 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 132.1/152.1 MB 7.1 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 132.1/152.1 MB 7.1 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 132.1/152.1 MB 7.1 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 132.1/152.1 MB 7.1 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 132.1/152.1 MB 7.1 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 132.1/152.1 MB 7.1 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 132.2/152.1 MB 6.0 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 132.8/152.1 MB 6.0 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 133.2/152.1 MB 6.0 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 133.2/152.1 MB 6.0 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 133.2/152.1 MB 6.0 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 133.2/152.1 MB 6.0 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 133.2/152.1 MB 5.4 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 133.4/152.1 MB 5.3 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 133.9/152.1 MB 5.3 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 134.3/152.1 MB 5.2 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 134.9/152.1 MB 5.2 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 135.2/152.1 MB 5.2 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 135.8/152.1 MB 5.2 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 136.3/152.1 MB 5.1 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 136.8/152.1 MB 5.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 137.4/152.1 MB 5.7 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 137.8/152.1 MB 5.7 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 138.2/152.1 MB 6.5 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 138.7/152.1 MB 6.5 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 139.2/152.1 MB 6.5 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 139.4/152.1 MB 6.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 139.5/152.1 MB 6.3 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 139.5/152.1 MB 6.3 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 139.5/152.1 MB 5.9 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 140.0/152.1 MB 5.9 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 140.5/152.1 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 140.5/152.1 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 140.5/152.1 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 140.5/152.1 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 140.5/152.1 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 140.5/152.1 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 140.5/152.1 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 140.9/152.1 MB 5.3 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 141.4/152.1 MB 5.3 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 141.6/152.1 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 141.6/152.1 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 141.6/152.1 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 141.6/152.1 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 141.6/152.1 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 141.6/152.1 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 141.6/152.1 MB 4.6 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 142.0/152.1 MB 4.5 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 142.4/152.1 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 142.8/152.1 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 143.3/152.1 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 143.7/152.1 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 144.4/152.1 MB 5.9 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 144.9/152.1 MB 5.9 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 145.1/152.1 MB 5.8 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 145.5/152.1 MB 5.8 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 146.0/152.1 MB 5.8 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 146.6/152.1 MB 5.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 147.0/152.1 MB 5.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 147.4/152.1 MB 5.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 148.0/152.1 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  148.4/152.1 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  148.9/152.1 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  149.4/152.1 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  150.0/152.1 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  150.7/152.1 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  151.4/152.1 MB 8.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.0/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  152.1/152.1 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 152.1/152.1 MB 3.0 MB/s eta 0:00:00\n",
      "Using cached torch-2.3.1-cp39-cp39-win_amd64.whl (159.7 MB)\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Using cached tiktoken-0.7.0-cp39-cp39-win_amd64.whl (798 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl (228.5 MB)\n",
      "Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl (3.5 MB)\n",
      "Using cached tbb-2021.13.0-py3-none-win_amd64.whl (286 kB)\n",
      "Using cached referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.19.0-cp39-none-win_amd64.whl (211 kB)\n",
      "   ---------------------------------------- 0.0/211.7 kB ? eta -:--:--\n",
      "   ------------------------------------- - 204.8/211.7 kB 13.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 211.7/211.7 kB 4.4 MB/s eta 0:00:00\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/6.2 MB 9.2 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.1/6.2 MB 13.5 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 1.8/6.2 MB 14.3 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.5/6.2 MB 14.8 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 3.3/6.2 MB 14.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 3.8/6.2 MB 14.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.6/6.2 MB 14.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.3/6.2 MB 14.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.0/6.2 MB 14.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.2/6.2 MB 15.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.2/6.2 MB 15.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 11.6 MB/s eta 0:00:00\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Building wheels for collected packages: fire\n",
      "  Building wheel for fire (setup.py): started\n",
      "  Building wheel for fire (setup.py): finished with status 'done'\n",
      "  Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117047 sha256=04f1f9ed0b6823b57e3b9e706116249392ad2c04c6373e07025d53b902ff2730\n",
      "  Stored in directory: c:\\users\\aadhi\\appdata\\local\\pip\\cache\\wheels\\ec\\ce\\ba\\9d5764d2266c500c18776c7d8f1e3c023075994cbc6dea47db\n",
      "Successfully built fire\n",
      "Installing collected packages: tbb, sentencepiece, mpmath, intel-openmp, sympy, rpds-py, pydantic-core, networkx, mkl, jinja2, fire, docstring-parser, attrs, annotated-types, torch, tiktoken, simple-parsing, referencing, pydantic, xformers, jsonschema-specifications, jsonschema, mistral_common, mistral_inference\n",
      "Successfully installed annotated-types-0.7.0 attrs-23.2.0 docstring-parser-0.16 fire-0.6.0 intel-openmp-2021.4.0 jinja2-3.1.4 jsonschema-4.21.1 jsonschema-specifications-2023.12.1 mistral_common-1.3.2 mistral_inference-1.3.0 mkl-2021.4.0 mpmath-1.3.0 networkx-3.2.1 pydantic-2.6.1 pydantic-core-2.16.2 referencing-0.35.1 rpds-py-0.19.0 sentencepiece-0.2.0 simple-parsing-0.1.5 sympy-1.13.1 tbb-2021.13.0 tiktoken-0.7.0 torch-2.3.1 xformers-0.0.27\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script isympy.exe is installed in 'C:\\Users\\aadhi\\anaconda3\\envs\\tf\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts convert-caffe2-to-onnx.exe, convert-onnx-to-caffe2.exe and torchrun.exe are installed in 'C:\\Users\\aadhi\\anaconda3\\envs\\tf\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script jsonschema.exe is installed in 'C:\\Users\\aadhi\\anaconda3\\envs\\tf\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts mistral-chat.exe and mistral-demo.exe are installed in 'C:\\Users\\aadhi\\anaconda3\\envs\\tf\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "%pip install mistral_inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b4ba854d964bbc955c6f2e37fa9b28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# This will prompt you to enter your token\n",
    "login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.42.4-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.24.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in c:\\users\\aadhi\\anaconda3\\envs\\tf\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\aadhi\\anaconda3\\envs\\tf\\lib\\site-packages (from transformers) (23.2)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Using cached PyYAML-6.0.1-cp39-cp39-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2024.5.15-cp39-cp39-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\aadhi\\anaconda3\\envs\\tf\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Using cached safetensors-0.4.3-cp39-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Using cached tokenizers-0.19.1-cp39-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.23.2->transformers)\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\aadhi\\anaconda3\\envs\\tf\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\aadhi\\anaconda3\\envs\\tf\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aadhi\\anaconda3\\envs\\tf\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aadhi\\anaconda3\\envs\\tf\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aadhi\\anaconda3\\envs\\tf\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aadhi\\anaconda3\\envs\\tf\\lib\\site-packages (from requests->transformers) (2024.6.2)\n",
      "Using cached transformers-4.42.4-py3-none-any.whl (9.3 MB)\n",
      "Downloading huggingface_hub-0.24.0-py3-none-any.whl (419 kB)\n",
      "   ---------------------------------------- 0.0/419.0 kB ? eta -:--:--\n",
      "   --- ----------------------------------- 41.0/419.0 kB 991.0 kB/s eta 0:00:01\n",
      "   -------- ------------------------------- 92.2/419.0 kB 1.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 225.3/419.0 kB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 256.0/419.0 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  409.6/419.0 kB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 419.0/419.0 kB 1.7 MB/s eta 0:00:00\n",
      "Using cached PyYAML-6.0.1-cp39-cp39-win_amd64.whl (152 kB)\n",
      "Using cached regex-2024.5.15-cp39-cp39-win_amd64.whl (269 kB)\n",
      "Using cached safetensors-0.4.3-cp39-none-win_amd64.whl (287 kB)\n",
      "Using cached tokenizers-0.19.1-cp39-none-win_amd64.whl (2.2 MB)\n",
      "Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Downloading filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "   ---------------------------------------- 0.0/177.6 kB ? eta -:--:--\n",
      "   -------------------------------- ------- 143.4/177.6 kB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 177.6/177.6 kB 2.7 MB/s eta 0:00:00\n",
      "Installing collected packages: tqdm, safetensors, regex, pyyaml, fsspec, filelock, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed filelock-3.15.4 fsspec-2024.6.1 huggingface-hub-0.24.0 pyyaml-6.0.1 regex-2024.5.15 safetensors-0.4.3 tokenizers-0.19.1 tqdm-4.66.4 transformers-4.42.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tqdm.exe is installed in 'C:\\Users\\aadhi\\anaconda3\\envs\\tf\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script huggingface-cli.exe is installed in 'C:\\Users\\aadhi\\anaconda3\\envs\\tf\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script transformers-cli.exe is installed in 'C:\\Users\\aadhi\\anaconda3\\envs\\tf\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 4.42.4\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: C:\\Users\\aadhi\\anaconda3\\Lib\\site-packages\n",
      "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
      "Required-by: auto_gptq, peft, sentence-transformers\n"
     ]
    }
   ],
   "source": [
    "!pip show transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
